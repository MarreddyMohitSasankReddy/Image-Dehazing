{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.exposure import rescale_intensity\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clahe(img, clip_limit=5.0, grid_size=(1,1)):\n",
    "    # Get image dimensions\n",
    "    height, width = img.shape[:2]\n",
    "    # Divide the image into non-overlapping contextual regions\n",
    "    grid_rows, grid_cols = grid_size\n",
    "    grid_row_height = height // grid_rows\n",
    "    grid_col_width = width // grid_cols\n",
    "    # Create the output image\n",
    "    clahe_img = np.zeros_like(img)\n",
    "    # Perform CLAHE on each grid\n",
    "    for row in range(grid_rows):\n",
    "        for col in range(grid_cols):\n",
    "            # Get the grid region\n",
    "            grid_region = img[row*grid_row_height:(row+1)*grid_row_height, col*grid_col_width:(col+1)*grid_col_width]\n",
    "            # Get the histogram of the grid region\n",
    "            hist, _ = np.histogram(grid_region.ravel(), bins=256, range=(0, 255))\n",
    "            # Clip the histogram\n",
    "            clip_val = clip_limit * np.sum(hist)\n",
    "            n_clip = np.minimum(hist, clip_val)\n",
    "            # Calculate the average number of pixels to redistribute\n",
    "            avg_pixels = (np.sum(hist) - np.sum(n_clip)) / 256\n",
    "            # Redistribute the clipped pixels\n",
    "            remain_pixels = avg_pixels\n",
    "            for i in range(255, -1, -1):\n",
    "                if n_clip[i] > 0:\n",
    "                    redistribute = min(n_clip[i], remain_pixels)\n",
    "                    hist[i] += redistribute\n",
    "                    remain_pixels -= redistribute\n",
    "            # Calculate the cumulative density function\n",
    "            cdf = np.cumsum(hist)\n",
    "            cdf = 255 * cdf / cdf[-1]\n",
    "            # Map the original pixel values to the new values\n",
    "            grid_region = np.interp(grid_region, np.arange(256), cdf)\n",
    "            # Insert the grid region back into the output image\n",
    "            clahe_img[row*grid_row_height:(row+1)*grid_row_height, col*grid_col_width:(col+1)*grid_col_width] = grid_region\n",
    "    return clahe_img\n",
    "\n",
    "\n",
    "def clahe2(image):\n",
    "    hsv_image = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    hsv_image[:,:,2] = clahe(hsv_image[:,:,2],clip_limit = 5.0,grid_size = (1,1))\n",
    "    \n",
    "    image = cv2.cvtColor(hsv_image,cv2.COLOR_HSV2BGR)\n",
    "    for i in range(3):\n",
    "        image[:,:,i] = clahe(image[:,:,i],clip_limit = 5.0,grid_size = (1,1))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m img2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC://Users//bhari//Downloads//sip//CAP//CAP_normal_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 5\u001b[0m output1 \u001b[38;5;241m=\u001b[39m \u001b[43mclahe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m output2 \u001b[38;5;241m=\u001b[39m clahe2(img1)\n\u001b[0;32m      8\u001b[0m output3 \u001b[38;5;241m=\u001b[39m clahe(img2)\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mclahe\u001b[1;34m(img, clip_limit, grid_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclahe\u001b[39m(img, clip_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m, grid_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Get image dimensions\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     height, width \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Divide the image into non-overlapping contextual regions\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     grid_rows, grid_cols \u001b[38;5;241m=\u001b[39m grid_size\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for i in range(1,18):\n",
    "    img1 = cv2.imread('C://Users//bhari//Downloads//sip//dehazed//DCP_normal_'+str(i)+'.jpg')\n",
    "    img2 = cv2.imread('C://Users//bhari//Downloads//sip//CAP//CAP_normal_'+str(i)+'.jpg')\n",
    "    k=1\n",
    "    output1 = clahe(img1)\n",
    "    output2 = clahe2(img1)\n",
    "\n",
    "    output3 = clahe(img2)\n",
    "    output4 = clahe2(img2)\n",
    "    \n",
    "    cv2.imwrite('C://Users//bhari//Downloads//sip//CLAHE//DCP_Morphology//normalCLAHE_'+str(i)+'.jpg',output1)\n",
    "    cv2.imwrite('C://Users//bhari//Downloads//sip//CLAHE//DCP_Morphology//normalmCLAHE_'+str(i)+'.jpg',output2)\n",
    "\n",
    "    cv2.imwrite('C://Users//bhari//Downloads//sip//CLAHE//CAP_HLP//normalCLAHE_'+str(i)+'.jpg',output3)\n",
    "    cv2.imwrite('C://Users//bhari//Downloads//sip//CLAHE//CAP_HLP//normalmCLAHE_'+str(i)+'.jpg',output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
